{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare lists of the info that I want to scrape\n",
    "Last_Page = 19\n",
    "Game = []\n",
    "Year = []\n",
    "Genre = []\n",
    "Player_Rating = []\n",
    "Critic_Rating = []\n",
    "Publisher = []\n",
    "Domestic_Sales = []\n",
    "sales_pal = []\n",
    "sales_jp = []\n",
    "sales_ot = []\n",
    "sales_gl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Url for our query\n",
    "urlhead = 'http://www.vgchartz.com/gamedb/?page='\n",
    "urltail = '&console=&region=All&developer=&publisher=&genre=&boxart=Both&ownership=Both'\n",
    "urltail += '&results=1000&order=Sales&showtotalsales=0&showtotalsales=1&showpublisher=0'\n",
    "urltail += '&showpublisher=1&showvgchartzscore=0&shownasales=1&showdeveloper=1&showcriticscore=1'\n",
    "urltail += '&showpalsales=0&showpalsales=1&showreleasedate=1&showuserscore=1&showjapansales=1'\n",
    "urltail += '&showlastupdate=0&showothersales=1&showgenre=1&sort=GL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we go\n",
    "for page in range(1,Last_Page):\n",
    "    time.sleep(5)\n",
    "    surl = urlhead + str(page)+urltail\n",
    "    r = urllib.request.urlopen(surl).read()\n",
    "    soup = bs4.BeautifulSoup(r)\n",
    "    game_tags = list(filter(lambda x: x.attrs['href'].startswith('http://www.vgchartz.com/game/'),\n",
    "                            soup.find_all('a')))[10:]\n",
    "    game_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 1\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Page: 8\n",
      "Page: 9\n",
      "Page: 10\n",
      "Page: 11\n",
      "Page: 12\n",
      "Page: 13\n",
      "Page: 14\n",
      "Page: 15\n",
      "Page: 16\n",
      "Page: 17\n",
      "Page: 18\n",
      "0\n",
      "Index(['Rank', 'Name', 'Platform', 'Year', 'Genre', 'Critic_Score',\n",
      "       'User_Score', 'Publisher', 'Developer', 'NA_Sales', 'PAL_Sales',\n",
      "       'JP_Sales', 'Other_Sales', 'Global_Sales'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, element\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "pages = 19\n",
    "rec_count = 0\n",
    "rank = []\n",
    "gname = []\n",
    "platform = []\n",
    "year = []\n",
    "genre = []\n",
    "critic_score = []\n",
    "user_score = []\n",
    "publisher = []\n",
    "developer = []\n",
    "sales_na = []\n",
    "sales_pal = []\n",
    "sales_jp = []\n",
    "sales_ot = []\n",
    "sales_gl = []\n",
    "\n",
    "urlhead = 'http://www.vgchartz.com/gamedb/?page='\n",
    "urltail = '&console=&region=All&developer=&publisher=&genre=&boxart=Both&ownership=Both'\n",
    "urltail += '&results=1000&order=Sales&showtotalsales=0&showtotalsales=1&showpublisher=0'\n",
    "urltail += '&showpublisher=1&showvgchartzscore=0&shownasales=1&showdeveloper=1&showcriticscore=1'\n",
    "urltail += '&showpalsales=0&showpalsales=1&showreleasedate=1&showuserscore=1&showjapansales=1'\n",
    "urltail += '&showlastupdate=0&showothersales=1&showgenre=1&sort=GL'\n",
    "url=urlhead + str(1) + urltail\n",
    "for page in range(1, pages):\n",
    "    surl = urlhead + str(page) + urltail\n",
    "    r = urllib.request.urlopen(surl).read()\n",
    "    time.sleep(20)\n",
    "    soup = BeautifulSoup(r)\n",
    "    print(f\"Page: {page}\")\n",
    "\n",
    "    # vgchartz website is really weird so we have to search for\n",
    "    # <a> tags with game urls\n",
    "    game_tags = list(filter(\n",
    "        lambda x: x.attrs['href'].startswith('http://www.vgchartz.com/game/'),\n",
    "        # discard the first 10 elements because those\n",
    "        # links are in the navigation bar\n",
    "        soup.find_all(\"a\")\n",
    "    ))[10:]\n",
    "\n",
    "    for tag in game_tags:\n",
    "\n",
    "        # add name to list\n",
    "        gname.append(\" \".join(tag.string.split()))\n",
    "        print(f\"{rec_count + 1} Fetch data for game {gname[-1]}\")\n",
    "\n",
    "        # get different attributes\n",
    "        # traverse up the DOM tree\n",
    "        data = tag.parent.parent.find_all(\"td\")\n",
    "        rank.append(np.int32(data[0].string))\n",
    "        platform.append(data[3].find('img').attrs['alt'])\n",
    "        publisher.append(data[4].string)\n",
    "        developer.append(data[5].string)\n",
    "        critic_score.append(\n",
    "            float(data[6].string) if\n",
    "            not data[6].string.startswith(\"N/A\") else np.nan)\n",
    "        user_score.append(\n",
    "            float(data[7].string) if\n",
    "            not data[7].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_na.append(\n",
    "            float(data[9].string[:-1]) if\n",
    "            not data[9].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_pal.append(\n",
    "            float(data[10].string[:-1]) if\n",
    "            not data[10].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_jp.append(\n",
    "            float(data[11].string[:-1]) if\n",
    "            not data[11].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_ot.append(\n",
    "            float(data[12].string[:-1]) if\n",
    "            not data[12].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_gl.append(\n",
    "            float(data[8].string[:-1]) if\n",
    "            not data[8].string.startswith(\"N/A\") else np.nan)\n",
    "        release_year = data[13].string.split()[-1]\n",
    "        # different format for year\n",
    "        if release_year.startswith('N/A'):\n",
    "            year.append('N/A')\n",
    "        else:\n",
    "            if int(release_year) >= 80:\n",
    "                year_to_add = np.int32(\"19\" + release_year)\n",
    "            else:\n",
    "                year_to_add = np.int32(\"20\" + release_year)\n",
    "            year.append(year_to_add)\n",
    "\n",
    "        # go to every individual website to get genre info\n",
    "        url_to_game = tag.attrs['href']\n",
    "        site_raw = urllib.request.urlopen(url_to_game).read()\n",
    "        sub_soup = BeautifulSoup(site_raw, \"html.parser\")\n",
    "        # again, the info box is inconsistent among games so we\n",
    "        # have to find all the h2 and traverse from that to the genre name\n",
    "        h2s = sub_soup.find(\"div\", {\"id\": \"gameGenInfoBox\"}).find_all('h2')\n",
    "        # make a temporary tag here to search for the one that contains\n",
    "        # the word \"Genre\"\n",
    "        temp_tag = element.Tag\n",
    "        for h2 in h2s:\n",
    "            if h2.string == 'Genre':\n",
    "                temp_tag = h2\n",
    "        genre.append(temp_tag.next_sibling.string)\n",
    "\n",
    "        rec_count += 1\n",
    "\n",
    "columns = {\n",
    "    'Rank': rank,\n",
    "    'Name': gname,\n",
    "    'Platform': platform,\n",
    "    'Year': year,\n",
    "    'Genre': genre,\n",
    "    'Critic_Score': critic_score,\n",
    "    'User_Score': user_score,\n",
    "    'Publisher': publisher,\n",
    "    'Developer': developer,\n",
    "    'NA_Sales': sales_na,\n",
    "    'PAL_Sales': sales_pal,\n",
    "    'JP_Sales': sales_jp,\n",
    "    'Other_Sales': sales_ot,\n",
    "    'Global_Sales': sales_gl\n",
    "}\n",
    "print(rec_count)\n",
    "df = pd.DataFrame(columns)\n",
    "print(df.columns)\n",
    "df = df[[\n",
    "    'Rank', 'Name', 'Platform', 'Year', 'Genre',\n",
    "    'Publisher', 'Developer', 'Critic_Score', 'User_Score',\n",
    "    'NA_Sales', 'PAL_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']]\n",
    "df.to_csv(\"vgsales.csv\", sep=\",\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>PAL_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rank, Name, Platform, Year, Genre, Publisher, Developer, Critic_Score, User_Score, NA_Sales, PAL_Sales, JP_Sales, Other_Sales, Global_Sales]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
